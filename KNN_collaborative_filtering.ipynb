{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_collaborative_filtering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPuLqiebHagM",
        "colab_type": "code",
        "outputId": "d56152a2-fc92-4a2c-fff3-6fce3078f6e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "! pip install surprise "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1678600 sha256=7e795b8e741d2033362c90c1c5b942000e6746c0e92a9328a2e4c24d8f1aded9\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.0 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6tChTxwHya_",
        "colab_type": "code",
        "outputId": "c192e500-7dbd-4d60-aa5b-12f39c72d331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8cFA8SQHlRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise import NormalPredictor, Reader, Dataset, KNNBasic, KNNBaseline, accuracy\n",
        "from surprise.model_selection import train_test_split, LeaveOneOut\n",
        "from collections import defaultdict\n",
        "import csv, sys, os\n",
        "import numpy as np\n",
        "import itertools\n",
        "import random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqBbWQyMHmFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class EndorsementMeasures:\n",
        "\n",
        "    def MAE(predictions):\n",
        "        return accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "    def RMSE(predictions):\n",
        "        return accuracy.rmse(predictions, verbose=False)\n",
        "\n",
        "    def DominantRec(predictions, n=5, minimumRating=4.0):\n",
        "        topN = defaultdict(list)\n",
        "\n",
        "\n",
        "        for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "            if (estimatedRating >= minimumRating):\n",
        "                topN[int(userID)].append((int(movieID), estimatedRating))\n",
        "\n",
        "        for userID, ratings in topN.items():\n",
        "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "            topN[int(userID)] = ratings[:n]\n",
        "\n",
        "        return topN\n",
        "\n",
        "    def ShotQuota(topNPredicted, leftOutPredictions):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for leftOut in leftOutPredictions:\n",
        "            userID = leftOut[0]\n",
        "            leftOutMovieID = leftOut[1]\n",
        "            # Is it in the predicted top 10 for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == int(movieID)):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits += 1\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def AggregateShotQuota(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Only look at ability to recommend things the users actually liked...\n",
        "            if (actualRating >= ratingCutoff):\n",
        "                # Is it in the predicted top 10 for this user?\n",
        "                hit = False\n",
        "                for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                    if (int(leftOutMovieID) == movieID):\n",
        "                        hit = True\n",
        "                        break\n",
        "                if (hit) :\n",
        "                    hits += 1\n",
        "\n",
        "                total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def ValuationShotQuota(topNPredicted, leftOutPredictions):\n",
        "        hits = defaultdict(float)\n",
        "        total = defaultdict(float)\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits[actualRating] += 1\n",
        "\n",
        "            total[actualRating] += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        for rating in sorted(hits.keys()):\n",
        "            print (rating, hits[rating] / total[rating])\n",
        "\n",
        "    def MedianComplementaryShotQuota(topNPredicted, leftOutPredictions):\n",
        "        summation = 0\n",
        "        total = 0\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hitRank = 0\n",
        "            rank = 0\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                rank = rank + 1\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hitRank = rank\n",
        "                    break\n",
        "            if (hitRank > 0) :\n",
        "                summation += 1.0 / hitRank\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        return summation / total\n",
        "\n",
        "    # What percentage of users have at least one \"good\" recommendation\n",
        "    def CustomerReport(topNPredicted, numUsers, ratingThreshold=0):\n",
        "        hits = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[userID]:\n",
        "                if (predictedRating >= ratingThreshold):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit):\n",
        "                hits += 1\n",
        "\n",
        "        return hits / numUsers\n",
        "\n",
        "    def Dissimilarity(topNPredicted, simsAlgo):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        simsMatrix = simsAlgo.compute_similarities()\n",
        "        for userID in topNPredicted.keys():\n",
        "            pairs = itertools.combinations(topNPredicted[userID], 2)\n",
        "            for pair in pairs:\n",
        "                movie1 = pair[0][0]\n",
        "                movie2 = pair[1][0]\n",
        "                innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
        "                innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
        "                similarity = simsMatrix[innerID1][innerID2]\n",
        "                total += similarity\n",
        "                n += 1\n",
        "\n",
        "        S = total / n\n",
        "        return (1-S)\n",
        "\n",
        "    def Freshness(topNPredicted, rankings):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            for rating in topNPredicted[userID]:\n",
        "                movieID = rating[0]\n",
        "                rank = rankings[movieID]\n",
        "                total += rank\n",
        "                n += 1\n",
        "        return total / n\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vqtKE6lH1pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AppraiseMethod:\n",
        "\n",
        "    def __init__(self, algorithm, name):\n",
        "        self.algorithm = algorithm\n",
        "        self.name = name\n",
        "\n",
        "    def Appraise(self, evaluationData, doTopN, n=5, verbose=True):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "        if (verbose):\n",
        "            print(\"Evaluating accuracy...\")\n",
        "        self.algorithm.fit(evaluationData.Training())\n",
        "        predictions = self.algorithm.test(evaluationData.Testing())\n",
        "        metrics[\"RMSE\"] = EndorsementMeasures.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = EndorsementMeasures.MAE(predictions)\n",
        "\n",
        "        if (doTopN):\n",
        "            # Appraise top-10 with Leave One Out testing\n",
        "            if (verbose):\n",
        "                print(\"Evaluating top-N with leave-one-out...\")\n",
        "            self.algorithm.fit(evaluationData.LeaveOneOutTraing())\n",
        "            leftOutPredictions = self.algorithm.test(evaluationData.LeaveOneOutTesting())\n",
        "            # Build predictions for all ratings not in the training set\n",
        "            allPredictions = self.algorithm.test(evaluationData.LeaveOneOutTestingOppositeTesting())\n",
        "            # Compute top 10 recs for each user\n",
        "            topNPredicted = EndorsementMeasures.DominantRec(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Computing hit-rate and rank metrics...\")\n",
        "            # See how often we recommended a movie the user actually rated\n",
        "            metrics[\"HR\"] = EndorsementMeasures.ShotQuota(topNPredicted, leftOutPredictions)\n",
        "            # See how often we recommended a movie the user actually liked\n",
        "            metrics[\"cHR\"] = EndorsementMeasures.AggregateShotQuota(topNPredicted, leftOutPredictions)\n",
        "            # Compute ARHR\n",
        "            metrics[\"ARHR\"] = EndorsementMeasures.MedianComplementaryShotQuota(topNPredicted, leftOutPredictions)\n",
        "\n",
        "            # Appraise properties of recommendations on full training set\n",
        "            if (verbose):\n",
        "                print(\"Computing recommendations with full data set...\")\n",
        "            self.algorithm.fit(evaluationData.EntireTraining())\n",
        "            allPredictions = self.algorithm.test(evaluationData.EntireTesting())\n",
        "            topNPredicted = EndorsementMeasures.DominantRec(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Analyzing coverage, diversity, and novelty...\")\n",
        "            # Print user coverage with a minimum predicted rating of 4.0:\n",
        "            metrics[\"Coverage\"] = EndorsementMeasures.CustomerReport(topNPredicted,\n",
        "                                                                  evaluationData.EntireTraining().n_users,\n",
        "                                                                  ratingThreshold=4.0)\n",
        "            # Measure diversity of recommendations:\n",
        "            metrics[\"Dissimilarity\"] = EndorsementMeasures.Dissimilarity(topNPredicted, evaluationData.Closeness())\n",
        "\n",
        "            # Measure novelty (average popularity rank of recommendations):\n",
        "            metrics[\"Freshness\"] = EndorsementMeasures.Freshness(topNPredicted,\n",
        "                                                            evaluationData.Celebrity())\n",
        "\n",
        "        if (verbose):\n",
        "            print(\"Analysis complete.\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def Label(self):\n",
        "        return self.name\n",
        "\n",
        "    def Method(self):\n",
        "        return self.algorithm\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUrGK6Y5H7kL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Appraisal:\n",
        "\n",
        "    def __init__(self, data, popularityRankings):\n",
        "        self.rankings = popularityRankings\n",
        "\n",
        "        # Build a full training set for evaluating overall properties\n",
        "        self.fullTrainSet = data.build_full_trainset()\n",
        "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
        "\n",
        "        # Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
        "\n",
        "        # Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
        "        # And build an anti-test-set for building predictions\n",
        "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
        "        for train, test in LOOCV.split(data):\n",
        "            self.LOOCVTrain = train\n",
        "            self.LOOCVTest = test\n",
        "\n",
        "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
        "\n",
        "        # Compute similarty matrix between items so we can measure diversity\n",
        "        sim_options = {'name': 'cosine', 'user_based': False}\n",
        "        self.simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "        self.simsAlgo.fit(self.fullTrainSet)\n",
        "\n",
        "    def EntireTraining(self):\n",
        "        return self.fullTrainSet\n",
        "\n",
        "    def EntireTesting(self):\n",
        "        return self.fullAntiTestSet\n",
        "\n",
        "    def OppositeTesting(self, USER):\n",
        "        trainset = self.fullTrainSet\n",
        "        fill = trainset.global_mean\n",
        "        anti_testset = []\n",
        "        u = trainset.to_inner_uid(str(USER))\n",
        "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
        "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
        "                         i in trainset.all_items() if\n",
        "                         i not in user_items]\n",
        "        return anti_testset\n",
        "\n",
        "    def Training(self):\n",
        "        return self.trainSet\n",
        "\n",
        "    def Testing(self):\n",
        "        return self.testSet\n",
        "\n",
        "    def LeaveOneOutTraing(self):\n",
        "        return self.LOOCVTrain\n",
        "\n",
        "    def LeaveOneOutTesting(self):\n",
        "        return self.LOOCVTest\n",
        "\n",
        "    def LeaveOneOutTestingOppositeTesting(self):\n",
        "        return self.LOOCVAntiTestSet\n",
        "\n",
        "    def Closeness(self):\n",
        "        return self.simsAlgo\n",
        "\n",
        "    def Celebrity(self):\n",
        "        return self.rankings\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpKyNaX7H-tK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Films:\n",
        "    film_Label = {}\n",
        "    label_Film = {}\n",
        "    link1 = '/content/drive/My Drive/ml-latest-small/ratings_after_wrangling.csv'\n",
        "    link2 = '/content/drive/My Drive/ml-latest-small/movies.csv'\n",
        "\n",
        "    def download(self):\n",
        "\n",
        "        # Look for files relative to the directory we are running from\n",
        "        os.chdir(os.path.dirname(sys.argv[0]))\n",
        "\n",
        "        ratingsDataset = 0\n",
        "        self.film_Label = {}\n",
        "        self.label_Film = {}\n",
        "\n",
        "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "\n",
        "        ratingsDataset = Dataset.load_from_file(self.link1, reader=reader)\n",
        "\n",
        "        with open(self.link2, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)  # Skip header line\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                movieName = row[1]\n",
        "                self.film_Label[movieID] = movieName\n",
        "                self.label_Film[movieName] = movieID\n",
        "\n",
        "        return ratingsDataset\n",
        "\n",
        "\n",
        "    def celebrity(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = defaultdict(int)\n",
        "        with open(self.link1, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                movieID = int(row[1])\n",
        "                ratings[movieID] += 1\n",
        "        rank = 1\n",
        "        for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[movieID] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "\n",
        "\n",
        "    def filmLabel(self, movieID):\n",
        "        if movieID in self.film_Label:\n",
        "            return self.film_Label[movieID]\n",
        "        else:\n",
        "            return \"\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzdjmq8sIBrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class referee:\n",
        "    algorithms = []\n",
        "\n",
        "    def __init__(self, dataset, rankings):\n",
        "        ed = Appraisal(dataset, rankings)\n",
        "        self.dataset = ed\n",
        "\n",
        "    def SumMethod(self, algorithm, name):\n",
        "        alg = AppraiseMethod(algorithm, name)\n",
        "        self.algorithms.append(alg)\n",
        "\n",
        "    def Appraise(self, doTopN):\n",
        "        results = {}\n",
        "        for algorithm in self.algorithms:\n",
        "            print(\"Evaluating \", algorithm.Label(), \"...\")\n",
        "            results[algorithm.Label()] = algorithm.Appraise(self.dataset, doTopN)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\")\n",
        "\n",
        "        if (doTopN):\n",
        "            print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\n",
        "                \"Algorithm\", \"RMSE\", \"MAE\", \"HR\", \"cHR\", \"ARHR\", \"Coverage\", \"Dissimilarity\", \"Freshness\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
        "                    name, metrics[\"RMSE\"], metrics[\"MAE\"], metrics[\"HR\"], metrics[\"cHR\"], metrics[\"ARHR\"],\n",
        "                    metrics[\"Coverage\"], metrics[\"Dissimilarity\"], metrics[\"Freshness\"]))\n",
        "        else:\n",
        "            print(\"{:<10} {:<10} {:<10}\".format(\"Algorithm\", \"RMSE\", \"MAE\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f}\".format(name, metrics[\"RMSE\"], metrics[\"MAE\"]))\n",
        "\n",
        "        print(\"\\nLegend:\\n\")\n",
        "        print(\"RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\")\n",
        "        print(\"MAE:       Mean Absolute Error. Lower values mean better accuracy.\")\n",
        "        if (doTopN):\n",
        "            print(\"HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\")\n",
        "            print(\n",
        "                \"cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\")\n",
        "            print(\n",
        "                \"ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\")\n",
        "            print(\n",
        "                \"Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\")\n",
        "            print(\n",
        "                \"Dissimilarity: 1-S, where S is the average similarity score between every possible pair of recommendations\")\n",
        "            print(\"           for a given user. Higher means more diverse.\")\n",
        "            print(\"Freshness:   Average popularity rank of recommended items. Higher means more novel.\")\n",
        "\n",
        "    def Endorsement(self, ml, USER=85, k=10):\n",
        "\n",
        "        for algo in self.algorithms:\n",
        "            print(\"\\nUsing recommender \", algo.Label())\n",
        "\n",
        "            print(\"\\nBuilding recommendation model...\")\n",
        "            trainSet = self.dataset.EntireTraining()\n",
        "            algo.Method().fit(trainSet)\n",
        "\n",
        "            print(\"Computing recommendations...\")\n",
        "            testSet = self.dataset.OppositeTesting(USER)\n",
        "\n",
        "            predictions = algo.Method().test(testSet)\n",
        "\n",
        "            recommendations = []\n",
        "\n",
        "            print(\"\\nWe recommend:\")\n",
        "            for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "                intMovieID = int(movieID)\n",
        "                recommendations.append((intMovieID, estimatedRating))\n",
        "\n",
        "            recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            for ratings in recommendations[:5]:\n",
        "                print(ml.filmLabel(ratings[0]), ratings[1])\n",
        "\n",
        "def Amount():\n",
        "    ml = Films()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.download()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.celebrity()\n",
        "    return (ml, data, rankings)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-y3NbrRIOW9",
        "colab_type": "text"
      },
      "source": [
        "# DashBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBVCNaQyIPhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDi26TyAgFQE",
        "colab_type": "text"
      },
      "source": [
        "Load up common data set for the recommender algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGsf5mdZgD5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e71e7f0e-b22c-4782-8465-5634a54d00d5"
      },
      "source": [
        "(ml, evaluationData, rankings) = Amount()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unJlDlZ1gPIj",
        "colab_type": "text"
      },
      "source": [
        "Construct an referee to, you know, evaluate them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH9dOL-BgNXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "679cc96d-1e0c-4cfe-a0c3-b596da2c5c9d"
      },
      "source": [
        "evaluator = referee(evaluationData, rankings)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdbp3wBYgUd7",
        "colab_type": "text"
      },
      "source": [
        "User-based KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8panK61IgTy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UserKNN = KNNBasic(sim_options = {'name': 'cosine', 'user_based': True})\n",
        "evaluator.SumMethod(UserKNN, \"User KNN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDIhRmrXgkU0",
        "colab_type": "text"
      },
      "source": [
        "Item-based KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_8Id_8wgiWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ItemKNN = KNNBasic(sim_options = {'name': 'cosine', 'user_based': False})\n",
        "evaluator.SumMethod(ItemKNN, \"Item KNN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wj1ZPtDgsN5",
        "colab_type": "text"
      },
      "source": [
        "Just make random recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcNhTALMgpfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Random = NormalPredictor()\n",
        "evaluator.SumMethod(Random, \"Random\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfxYCGYcg6p2",
        "colab_type": "text"
      },
      "source": [
        "Fight!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gTIDGizgy50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8a9f047-edfc-4376-a0a2-417a08825a30"
      },
      "source": [
        "evaluator.Appraise(False)\n",
        "\n",
        "evaluator.Endorsement(ml)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating  User KNN ...\n",
            "Evaluating accuracy...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Item KNN ...\n",
            "Evaluating accuracy...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  User KNN ...\n",
            "Evaluating accuracy...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Item KNN ...\n",
            "Evaluating accuracy...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "User KNN   0.9802     0.7560    \n",
            "Item KNN   0.9749     0.7582    \n",
            "Random     1.4237     1.1385    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  User KNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Heidi Fleiss: Hollywood Madam (1995) 5\n",
            "Awfully Big Adventure, An (1995) 5\n",
            "In the Realm of the Senses (Ai no corrida) (1976) 5\n",
            "What Happened Was... (1994) 5\n",
            "Denise Calls Up (1995) 5\n",
            "\n",
            "Using recommender  Item KNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Two if by Sea (1996) 5\n",
            "Awfully Big Adventure, An (1995) 5\n",
            "Love & Human Remains (1993) 5\n",
            "Fluke (1995) 5\n",
            "Inkwell, The (1994) 5\n",
            "\n",
            "Using recommender  Random\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Sabrina (1995) 5\n",
            "Dracula: Dead and Loving It (1995) 5\n",
            "Balto (1995) 5\n",
            "Mortal Kombat (1995) 5\n",
            "Usual Suspects, The (1995) 5\n",
            "\n",
            "Using recommender  User KNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Heidi Fleiss: Hollywood Madam (1995) 5\n",
            "Awfully Big Adventure, An (1995) 5\n",
            "In the Realm of the Senses (Ai no corrida) (1976) 5\n",
            "What Happened Was... (1994) 5\n",
            "Denise Calls Up (1995) 5\n",
            "\n",
            "Using recommender  Item KNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Two if by Sea (1996) 5\n",
            "Awfully Big Adventure, An (1995) 5\n",
            "Love & Human Remains (1993) 5\n",
            "Fluke (1995) 5\n",
            "Inkwell, The (1994) 5\n",
            "\n",
            "Using recommender  Random\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Sudden Death (1995) 5\n",
            "GoldenEye (1995) 5\n",
            "Balto (1995) 5\n",
            "Get Shorty (1995) 5\n",
            "To Die For (1995) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIUvh1kQg9Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}